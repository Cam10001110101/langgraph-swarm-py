{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! pip install langchain-mcp-adapters langgraph \"langchain[anthropic]\" langgraph-swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_anthropic'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Imports\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_anthropic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatAnthropic\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_mcp_adapters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiServerMCPClient\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprebuilt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_anthropic'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_swarm import create_handoff_tool, create_swarm\n",
    "\n",
    "planner_prompt = \"\"\"\n",
    "<Task>\n",
    "You will help plan the steps to implement a LangGraph application. \n",
    "</Task>\n",
    "\n",
    "<Instructions>\n",
    "1. Reflect on the user's request. \n",
    "2. Use the list_doc_sources tool to fetch and the fetch_docs tool to read the llms.txt file.\n",
    "3. Identify documents that are relevant to the user's request.\n",
    "4. Ask follow-up questions to help refine the project scope and narrow the set of documents to be used for the project.\n",
    "5. When the project scope is clear produce a short description of the project with relevant URLs.\n",
    "6. Finally, transfer to transfer_to_researcher_agent.\n",
    "</Instructions>\n",
    "\"\"\"\n",
    "\n",
    "researcher_prompt = \"\"\"\n",
    "<Task>\n",
    "You will perform research on the project scope. \n",
    "</Task>\n",
    "\n",
    "<Instructions>\n",
    "1. Reflect on the project scope and provided URLs from the planner.\n",
    "2. Use the fetch_docs tool to fetch and read each URL.\n",
    "3. Use the information in these URLs to implement the solution to the user's request.\n",
    "4. If you need further clarification or additional sources to implement the solution, transfer to transfer_to_planner_agent.\n",
    "</Instructions>\n",
    "\"\"\"\n",
    "\n",
    "# LLM\n",
    "model = ChatAnthropic(model=\"claude-3-7-sonnet-latest\")\n",
    "\n",
    "# Handoff tools\n",
    "transfer_to_planner_agent = create_handoff_tool(\n",
    "    agent_name=\"planner_agent\",\n",
    "    description=\"Transfer user to the planner_agent to address clarifying questions or help them plan the steps to complete the user's request.\"\n",
    ")\n",
    "transfer_to_researcher_agent = create_handoff_tool(\n",
    "    agent_name=\"researcher_agent\",\n",
    "    description=\"Transfer user to researcher_agent to perform research on the user's request.\"\n",
    ")\n",
    "\n",
    "# TODO: Move to configuration\n",
    "#configurable = Configuration.from_runnable_config(config)\n",
    "#llms_txt_urls = configurable.llms_txt\n",
    "llms_txt_urls = \"LangGraph:https://langchain-ai.github.io/langgraph/llms.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \n",
    "messages = {\"role\": \"user\", \"content\": \"Create a prompt chain that makes and improves a joke based on the user's input.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research and planning tools \n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"research-server\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"@playwright/mcp\"],\n",
    "            \"transport\": \"stdio\",\n",
    "            \"env\": {\n",
    "                \"PATH\": \"/Users/rlm/.cursor/extensions/ms-python.python-2024.12.3-darwin-arm64/python_files/deactivate/zsh:/Users/rlm/Desktop/Code/langgraph-swarm/.venv/bin:/Users/rlm/.bun/bin:/Users/rlm/.poetry/bin:/Users/rlm/Library/Python/3.13/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/Users/rlm/.cargo/bin:/Users/rlm/miniforge3/condabin:/Users/rlm/.local/bin\"\n",
    "            }\n",
    "        },\n",
    "        \"planning-server\": {\n",
    "            \"command\": \"uvx\",\n",
    "            \"args\": [\n",
    "            \"--from\",\n",
    "            \"mcpdoc\",\n",
    "            \"mcpdoc\",\n",
    "            \"--urls\",\n",
    "            llms_txt_urls,\n",
    "            \"--transport\",\n",
    "            \"stdio\",\n",
    "            \"--port\",\n",
    "            \"8081\",\n",
    "            \"--host\",\n",
    "            \"localhost\"\n",
    "            ],\n",
    "            \"transport\": \"stdio\",\n",
    "        }\n",
    "    }\n",
    "\n",
    ") as client:\n",
    "    # Planner agent\n",
    "    planner_agent = create_react_agent(model,\n",
    "                                       prompt=planner_prompt, \n",
    "                                       tools=client.server_name_to_tools[\"planning-server\"].append(transfer_to_researcher_agent),\n",
    "                                       name=\"planner_agent\") \n",
    "\n",
    "    # Researcher agent\n",
    "    researcher_agent = create_react_agent(model, \n",
    "                                          prompt=researcher_prompt, \n",
    "                                          tools=client.server_name_to_tools[\"research-server\"].append(transfer_to_planner_agent),\n",
    "                                          name=\"researcher_agent\") \n",
    "\n",
    "    # Swarm\n",
    "    agent_swarm = create_swarm([planner_agent, researcher_agent], default_active_agent=\"planner_agent\")\n",
    "\n",
    "    # app = agent_swarm.compile(config_schema=Configuration)\n",
    "    agent = agent_swarm.compile()\n",
    "    response = await agent.ainvoke({\"messages\": messages})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for m in agent_response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
